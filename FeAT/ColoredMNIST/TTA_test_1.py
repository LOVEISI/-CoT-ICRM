import torch
import torch.nn as nn
import torch.optim as optim
from mydatasets import coloredmnist
from models import MLP, TopMLP
import argparse
import matplotlib.pyplot as plt

# ----------------- æ›´æ–° BN running stats -----------------
def update_bn_stats(model, data):
    model.train()
    with torch.no_grad():
        _ = model(data)

# ----------------- ç†µè®¡ç®—å‡½æ•° -----------------
def entropy_loss_fn(logits):
    probs = torch.sigmoid(logits)
    return - (probs * torch.log(probs + 1e-8) + (1 - probs) * torch.log(1 - probs + 1e-8)).mean()

# ----------------- ä¸»å‡½æ•° -----------------
def main(args):
    # åŠ è½½ç›®æ ‡åŸŸæ•°æ®
    _, target_envs = coloredmnist(0.1, 0.2, 0.25, int_target=False)
    test_x = torch.cat([env['images'] for env in target_envs])
    test_y = torch.cat([env['labels'] for env in target_envs]).float().unsqueeze(1)

    # åŠ è½½æ¨¡å‹
    mlp = MLP(hidden_dim=128, input_dim=2 * 14 * 14)
    topmlp = TopMLP(hidden_dim=128, n_top_layers=1, n_targets=1)
    mlp.load_state_dict(torch.load(args.mlp_path))
    topmlp.load_state_dict(torch.load(args.topmlp_path))
    model = nn.Sequential(mlp, topmlp)

    # æ›´æ–°BNç»Ÿè®¡
    if args.use_bn:
        print("Updating BN statistics...")
        update_bn_stats(model, test_x)

    # è®¾ç½®å“ªäº›å‚æ•°éœ€è¦ä¼˜åŒ–
    if args.use_tent:
        print("Using Tent strategy: only updating BN parameters")
        for name, param in model.named_parameters():
            param.requires_grad = ("bn" in name.lower())
    else:
        for param in model.parameters():
            param.requires_grad = True

    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)

    # ---------- TTAè®­ç»ƒ ----------
    loss_history = []

    if args.use_entropy or args.use_tent:
        model.train()
        for epoch in range(args.epochs):
            logits = model(test_x)
            loss = entropy_loss_fn(logits)
            loss_history.append(loss.item())

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if epoch % 10 == 0 or epoch == args.epochs - 1:
                print(f"TTA Epoch {epoch}, Loss: {loss.item():.4f}")

    # ---------- è¯„ä¼° ----------
    model.eval()
    with torch.no_grad():
        logits = model(test_x)
        preds = (torch.sigmoid(logits) > 0.5).float()
        acc = (preds == test_y).float().mean().item()
        print(f"\nğŸš€ Target Domain Accuracy: {acc * 100:.2f}%")

    # ---------- ç»˜åˆ¶è®­ç»ƒ Loss ----------
    if loss_history:
        plt.plot(loss_history)
        plt.title("TTA Training Loss")
        plt.xlabel("Epoch")
        plt.ylabel("Entropy Loss")
        plt.grid(True)
        plt.tight_layout()
        plt.show()

# ----------------- CLI å…¥å£ -----------------
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--mlp_path', type=str, default="./feat_pretrained_model/mlp0.pth")
    parser.add_argument('--topmlp_path', type=str, default="./feat_pretrained_model/topmlp0.pth")
    parser.add_argument('--use_bn', action='store_true', help='æ›´æ–° BN running stats')
    parser.add_argument('--use_entropy', action='store_true', help='æ˜¯å¦ä½¿ç”¨ç†µæœ€å°åŒ–')
    parser.add_argument('--use_tent', action='store_true', help='æ˜¯å¦ä»…æ›´æ–°BNå‚æ•°ï¼ˆTentï¼‰')
    parser.add_argument('--epochs', type=int, default=300)
    args = parser.parse_args()

    main(args)
