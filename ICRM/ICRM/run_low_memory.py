#!/usr/bin/env python3
"""
å†…å­˜ä¼˜åŒ–çš„ICRMè¿è¡Œè„šæœ¬
ä¸“é—¨é’ˆå¯¹å†…å­˜ä¸è¶³çš„æƒ…å†µè¿›è¡Œä¼˜åŒ–
"""

import os
import sys
import torch
import gc

def optimize_memory():
    """å†…å­˜ä¼˜åŒ–è®¾ç½®"""
    # è®¾ç½®ç¯å¢ƒå˜é‡å‡å°‘å†…å­˜ä½¿ç”¨
    os.environ['OMP_NUM_THREADS'] = '1'
    os.environ['MKL_NUM_THREADS'] = '1'  
    os.environ['NUMEXPR_NUM_THREADS'] = '1'
    os.environ['OPENBLAS_NUM_THREADS'] = '1'
    
    # ç¦ç”¨æ•°æ®åŠ è½½å™¨çš„å¤šè¿›ç¨‹
    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
    
    # è®¾ç½®PyTorchå†…å­˜ç®¡ç†
    if torch.cuda.is_available():
        torch.backends.cudnn.benchmark = False
        torch.backends.cudnn.deterministic = True
    
    # å¼ºåˆ¶åƒåœ¾å›æ”¶
    gc.collect()
    
    print("=== å†…å­˜ä¼˜åŒ–è®¾ç½®å®Œæˆ ===")
    print(f"â€¢ çº¿ç¨‹æ•°é™åˆ¶ä¸º1")
    print(f"â€¢ ç¦ç”¨CUDAå¼‚æ­¥æ‰§è¡Œ") 
    print(f"â€¢ å¼ºåˆ¶åƒåœ¾å›æ”¶")

def run_with_low_memory():
    """è¿è¡ŒICRMï¼Œå†…å­˜ä¼˜åŒ–ç‰ˆæœ¬"""
    
    # å…ˆè¿›è¡Œå†…å­˜ä¼˜åŒ–
    optimize_memory()
    
    # å¯¼å…¥å¿…è¦æ¨¡å—ï¼ˆå»¶è¿Ÿå¯¼å…¥å‡å°‘åˆå§‹å†…å­˜å ç”¨ï¼‰
    print("=== å¼€å§‹å¯¼å…¥æ¨¡å— ===")
    try:
        import argparse
        import json
        print("âœ“ åŸºç¡€æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        import numpy as np  
        print("âœ“ NumPyå¯¼å…¥æˆåŠŸ")
        
        import torch
        print(f"âœ“ PyTorchå¯¼å…¥æˆåŠŸ (ç‰ˆæœ¬: {torch.__version__})")
        
        import utils
        import dataset as dataset_file  
        import hparams_registry
        import algorithms
        print("âœ“ ICRMæ¨¡å—å¯¼å…¥æˆåŠŸ")
        
    except Exception as e:
        print(f"âœ— æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    # è®¾ç½®å‚æ•°
    print("=== è®¾ç½®è¿è¡Œå‚æ•° ===")
    
    # å†…å­˜ä¼˜åŒ–çš„è¶…å‚æ•°
    hparams = hparams_registry.default_hparams('ICRM', 'ColouredMNIST')
    
    # å…³é”®è®¾ç½®
    hparams.update({
        'use_mosaic': True,           # å¯ç”¨Memory Mosaic
        'pretrained_model_path': 'G:/feta/FeAT/ColoredMNIST/mmmlp_best.pth',
        
        # å†…å­˜ä¼˜åŒ–è®¾ç½®
        'batch_size': 16,            # å‡å°batch size 
        'test_batch_size': 32,       # å‡å°test batch size
        'n_embd': 64,               # å‡å°embeddingç»´åº¦
        'n_layer': 4,               # å‡å°‘å±‚æ•°
        'n_head': 4,                # å‡å°‘æ³¨æ„åŠ›å¤´æ•°
        'pmem_size': 512,           # å‡å°æŒä¹…è®°å¿†å¤§å°
        'pmem_count': 1,            # å‡å°‘æŒä¹…è®°å¿†æ•°é‡
        'context_length': 50,       # å‡å°ä¸Šä¸‹æ–‡é•¿åº¦
        
        # å…¶ä»–ä¼˜åŒ–
        'is_parallel': False,       # ç¦ç”¨å¹¶è¡Œ
        'device': 'cuda' if torch.cuda.is_available() else 'cpu'
    })
    
    print("å†…å­˜ä¼˜åŒ–å‚æ•°:")
    memory_params = ['batch_size', 'n_embd', 'n_layer', 'pmem_size', 'use_mosaic']
    for param in memory_params:
        print(f"  {param}: {hparams[param]}")
    
    # åˆ›å»ºæ•°æ®é›†
    print("=== åˆ›å»ºæ•°æ®é›† ===")
    try:
        dataset = dataset_file.get_dataset_class('ColouredMNIST')(
            root='/mnt/data02/gll_yong/ICRM/data/MNIST',  # ä½ çš„æ•°æ®è·¯å¾„
            test_envs=[2], 
            hparams=hparams
        )
        print("âœ“ æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âœ— æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥æ•°æ®è·¯å¾„æ˜¯å¦æ­£ç¡®")
        return False
    
    # åˆ›å»ºç®—æ³•
    print("=== åˆ›å»ºICRMç®—æ³• ===")
    try:
        algorithm = algorithms.ICRM(
            dataset.input_shape,
            dataset.num_classes, 
            hparams
        )
        print("âœ“ ICRMç®—æ³•åˆ›å»ºæˆåŠŸ")
        print(f"âœ“ æ¨¡å‹ç±»å‹: {type(algorithm.classifier).__name__}")
        
        # æ‰“å°æ¨¡å‹å‚æ•°æ•°é‡
        total_params = sum(p.numel() for p in algorithm.network.parameters())
        print(f"âœ“ æ€»å‚æ•°æ•°é‡: {total_params:,}")
        
    except Exception as e:
        print(f"âœ— ç®—æ³•åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\nğŸ‰ å†…å­˜ä¼˜åŒ–å¯åŠ¨æˆåŠŸï¼")
    print("ç°åœ¨å¯ä»¥è¿›è¡Œè®­ç»ƒæˆ–æµ‹è¯•äº†ã€‚")
    return True

if __name__ == "__main__":
    success = run_with_low_memory()
    
    if success:
        print("\n=== å†…å­˜ä½¿ç”¨å»ºè®® ===")
        print("1. å¦‚æœä»ç„¶å†…å­˜ä¸è¶³ï¼Œå¯ä»¥è¿›ä¸€æ­¥å‡å°:")
        print("   â€¢ batch_size (å½“å‰16ï¼Œå¯ä»¥è¯•8æˆ–4)")
        print("   â€¢ n_embd (å½“å‰64ï¼Œå¯ä»¥è¯•32)")
        print("   â€¢ pmem_size (å½“å‰512ï¼Œå¯ä»¥è¯•256)")
        print("2. ç›‘æ§ç³»ç»Ÿå†…å­˜ä½¿ç”¨æƒ…å†µ")
        print("3. è€ƒè™‘å¢åŠ è™šæ‹Ÿå†…å­˜å¤§å°")
    else:
        print("\n=== æ•…éšœæ’é™¤å»ºè®® ===")
        print("1. é‡å¯ç³»ç»Ÿé‡Šæ”¾å†…å­˜")
        print("2. å…³é—­å…¶ä»–ç¨‹åº")
        print("3. å¢åŠ è™šæ‹Ÿå†…å­˜:")
        print("   æ§åˆ¶é¢æ¿ â†’ ç³»ç»Ÿ â†’ é«˜çº§ç³»ç»Ÿè®¾ç½® â†’ æ€§èƒ½è®¾ç½® â†’ é«˜çº§ â†’ è™šæ‹Ÿå†…å­˜")
        print("4. å¦‚æœæœ‰ç‹¬ç«‹æ˜¾å¡ï¼Œç¡®ä¿PyTorchä½¿ç”¨GPUè€Œä¸æ˜¯CPU") 