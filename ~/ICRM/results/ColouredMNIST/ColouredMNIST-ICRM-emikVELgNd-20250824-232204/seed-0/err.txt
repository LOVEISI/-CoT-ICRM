Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/root/autodl-tmp/test/feta/ICRM/ICRM/main.py", line 220, in <module>
    val_metric_results = algorithm.evaluate(loader, cache = validation_cache[index])#val_metric_results 是评估结果，通常是一个字典，包含了各种性能指标（如准确率、损失等）                
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/test/feta/ICRM/ICRM/algorithms.py", line 747, in evaluate
    result = self._evaluate_robust(self.network, loader, self.hparams['metrics'],  cache)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/test/feta/ICRM/ICRM/algorithms.py", line 721, in _evaluate_robust
    p, _ = self.predict(x, y, return_context=True, past_key_values=past)  # p:[B,T,C]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/test/feta/ICRM/ICRM/algorithms.py", line 520, in predict
    outputs = self.classifier((x, y, None, past_key_values))  #记录了前面已经处理的数据对当前预测的影响
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/test/feta/ICRM/ICRM/networks.py", line 478, in forward
    outputs = self._backbone(inputs_embeds=embeds, past_key_values=past)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 875, in forward
    causal_mask = create_causal_mask(
                  ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/masking_utils.py", line 805, in create_causal_mask
    causal_mask = mask_interface(
                  ^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/masking_utils.py", line 449, in sdpa_mask_older_torch
    causal_mask |= torch.all(~causal_mask, dim=-1, keepdim=True)
RuntimeError: unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.
